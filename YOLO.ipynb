{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee39a852",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from ultralytics import settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cd9405",
   "metadata": {},
   "outputs": [],
   "source": [
    "#settings.reset()\n",
    "# View all settings\n",
    "print(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbae8333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.184  Python-3.12.10 torch-2.8.0+cpu CPU (12th Gen Intel Core(TM) i9-12900KF)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=E:/Techlabs_AI/digital_wardrobe/eWardrobe/datasets/YOLOsmall/YOLOsmall.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n-seg.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=E:/Techlabs_AI/digital_wardrobe/eWardrobe/YOLO/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=E:\\Techlabs_AI\\digital_wardrobe\\eWardrobe\\YOLO\\runs\\train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=13\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    685975  ultralytics.nn.modules.head.Segment          [13, 32, 64, [64, 128, 256]]  \n",
      "YOLO11n-seg summary: 203 layers, 2,845,143 parameters, 2,845,127 gradients, 9.7 GFLOPs\n",
      "\n",
      "Transferred 510/561 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 146.5130.2 MB/s, size: 59.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning E:\\Techlabs_AI\\digital_wardrobe\\eWardrobe\\datasets\\YOLOsmall\\train\\labels.cache... 100 images, 0 backgrounds, 0 corrupt: 100%|██████████| 100/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 131.830.1 MB/s, size: 31.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "e:\\Techlabs_AI\\digital_wardrobe\\eWardrobe\\YOLO\\venv312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning E:\\Techlabs_AI\\digital_wardrobe\\eWardrobe\\datasets\\YOLOsmall\\val\\labels.cache... 100 images, 0 backgrounds, 0 corrupt: 100%|██████████| 100/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to E:\\Techlabs_AI\\digital_wardrobe\\eWardrobe\\YOLO\\runs\\train\\labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "e:\\Techlabs_AI\\digital_wardrobe\\eWardrobe\\YOLO\\venv312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000588, momentum=0.9) with parameter groups 90 weight(decay=0.0), 101 weight(decay=0.0005), 100 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mE:\\Techlabs_AI\\digital_wardrobe\\eWardrobe\\YOLO\\runs\\train\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3         0G      1.369      5.708      4.177      1.643         21        640: 100%|██████████| 7/7 [00:13<00:00,  1.93s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        100        136       0.02       0.02     0.0276     0.0248       0.02       0.02     0.0276    0.00552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3         0G      1.158      4.783      4.135      1.488         12        640: 100%|██████████| 7/7 [00:12<00:00,  1.78s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        100        136     0.0391      0.129     0.0328     0.0204     0.0391      0.129     0.0354      0.017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3         0G      1.077      3.999      4.079      1.387         17        640: 100%|██████████| 7/7 [00:12<00:00,  1.81s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        100        136      0.019      0.307     0.0295      0.016     0.0165      0.242      0.028     0.0119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.014 hours.\n",
      "Optimizer stripped from E:\\Techlabs_AI\\digital_wardrobe\\eWardrobe\\YOLO\\runs\\train\\weights\\last.pt, 6.0MB\n",
      "Optimizer stripped from E:\\Techlabs_AI\\digital_wardrobe\\eWardrobe\\YOLO\\runs\\train\\weights\\best.pt, 6.0MB\n",
      "\n",
      "Validating E:\\Techlabs_AI\\digital_wardrobe\\eWardrobe\\YOLO\\runs\\train\\weights\\best.pt...\n",
      "Ultralytics 8.3.184  Python-3.12.10 torch-2.8.0+cpu CPU (12th Gen Intel Core(TM) i9-12900KF)\n",
      "YOLO11n-seg summary (fused): 113 layers, 2,837,103 parameters, 0 gradients, 9.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        100        136     0.0636      0.157     0.0459     0.0249     0.0636      0.157     0.0485     0.0234\n",
      "   short_sleeved_shirt         31         31        0.2     0.0323      0.105      0.063        0.2     0.0323      0.105      0.063\n",
      "    long_sleeved_shirt         17         17     0.0667      0.118     0.0468     0.0355     0.0667      0.118     0.0468      0.019\n",
      "                  vest          7          7          0          0          0          0          0          0          0          0\n",
      "                shorts          4          4    0.00309        0.5    0.00392    0.00157    0.00309        0.5    0.00392    0.00136\n",
      "              trousers         12         12        0.1     0.0833     0.0882     0.0793        0.1     0.0833     0.0882     0.0529\n",
      "                 skirt         29         29          0          0          0          0          0          0          0          0\n",
      "   short_sleeved_dress         25         25       0.25       0.04       0.13      0.013       0.25       0.04      0.156     0.0469\n",
      "    long_sleeved_dress          5          5     0.0165        0.8     0.0847     0.0566     0.0165        0.8     0.0847     0.0504\n",
      "            vest_dress          4          4          0          0          0          0          0          0          0          0\n",
      "           sling_dress          2          2          0          0          0          0          0          0          0          0\n",
      "Speed: 0.4ms preprocess, 29.1ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mE:\\Techlabs_AI\\digital_wardrobe\\eWardrobe\\YOLO\\runs\\train\u001b[0m\n",
      "Ultralytics 8.3.184  Python-3.12.10 torch-2.8.0+cpu CPU (12th Gen Intel Core(TM) i9-12900KF)\n",
      "YOLO11n-seg summary (fused): 113 layers, 2,837,103 parameters, 0 gradients, 9.6 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 328.0111.3 MB/s, size: 35.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning E:\\Techlabs_AI\\digital_wardrobe\\eWardrobe\\datasets\\YOLOsmall\\val\\labels.cache... 100 images, 0 backgrounds, 0 corrupt: 100%|██████████| 100/100 [00:00<?, ?it/s]\n",
      "e:\\Techlabs_AI\\digital_wardrobe\\eWardrobe\\YOLO\\venv312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:03<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        100        136     0.0478      0.146     0.0365     0.0198     0.0478      0.146     0.0393     0.0195\n",
      "   short_sleeved_shirt         31         31      0.167     0.0323     0.0872     0.0523      0.167     0.0323     0.0872     0.0523\n",
      "    long_sleeved_shirt         17         17          0          0          0          0          0          0          0          0\n",
      "                  vest          7          7          0          0          0          0          0          0          0          0\n",
      "                shorts          4          4    0.00319        0.5    0.00397    0.00159    0.00319        0.5    0.00397    0.00137\n",
      "              trousers         12         12     0.0909     0.0833      0.084     0.0756     0.0909     0.0833      0.084     0.0504\n",
      "                 skirt         29         29          0          0          0          0          0          0          0          0\n",
      "   short_sleeved_dress         25         25        0.2       0.04      0.104     0.0104        0.2       0.04      0.132     0.0396\n",
      "    long_sleeved_dress          5          5     0.0169        0.8      0.086     0.0582     0.0169        0.8      0.086     0.0514\n",
      "            vest_dress          4          4          0          0          0          0          0          0          0          0\n",
      "           sling_dress          2          2          0          0          0          0          0          0          0          0\n",
      "Speed: 0.3ms preprocess, 27.8ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mE:\\Techlabs_AI\\digital_wardrobe\\eWardrobe\\YOLO\\runs\\train2\u001b[0m\n",
      "\n",
      "image 1/1 E:\\Techlabs_AI\\Digital wardrop\\datasets\\small\\test\\000011.jpg: 640x480 (no detections), 55.4ms\n",
      "Speed: 1.7ms preprocess, 55.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "#this worked and should be the basis for the small dataset, the project variable forces YOLO to this root\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolo11n-seg.pt\")\n",
    "\n",
    "#pathdataset = \"E:/Techlabs_AI/Digital wardrop/datasets/YOLOsmall/YOLOsmall.yaml\"\n",
    "pathdataset = \"E:/Techlabs_AI/digital_wardrobe/eWardrobe/datasets/YOLOsmall/YOLOsmall.yaml\"\n",
    "\n",
    "\n",
    "# Train the model using the 'coco8.yaml' dataset for 3 epochs\n",
    "results = model.train(data=pathdataset, epochs=3, project=\"E:/Techlabs_AI/digital_wardrobe/eWardrobe/YOLO/runs\")\n",
    "\n",
    "# Evaluate the model's performance on the validation set\n",
    "results = model.val()\n",
    "\n",
    "# Perform object detection on an image using the model\n",
    "results = model(\"E:/Techlabs_AI/Digital wardrop/datasets/small/test/000011.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5e7ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#small model test\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolo11n-seg.yaml\")\n",
    "\n",
    "pathdataset = \"E:/Techlabs_AI/digital_wardrobe/eWardrobe/datasets/YOLOsmall/YOLOsmall.yaml\"\n",
    "\n",
    "# Train the model for 3 epochs\n",
    "results = model.train(data=pathdataset, epochs=3)\n",
    "\n",
    "# Evaluate the model's performance on the validation set\n",
    "results = model.val()\n",
    "\n",
    "# Perform object detection on an image using the model\n",
    "results = model(\"E:/Techlabs_AI/Digital wardrop/datasets/small/test/000011.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0082b892",
   "metadata": {},
   "source": [
    "The training settings for YOLO models encompass various hyperparameters and configurations used during the training process. These settings influence the model's performance, speed, and accuracy. Key training settings include batch size, learning rate, momentum, and weight decay. Additionally, the choice of optimizer, loss function, and training dataset composition can impact the training process. Careful tuning and experimentation with these settings are crucial for optimizing performance.\n",
    "\n",
    "| Argument       | Type              | Default | Description |\n",
    "|----------------|------------------|---------|-------------|\n",
    "| model          | str              | None    | Path to a `.pt` pretrained model or `.yaml` config file. Defines model structure or initializes weights. |\n",
    "| data           | str              | None    | Path to dataset config (e.g., `coco8.yaml`). Defines train/val data, class names, etc. |\n",
    "| epochs         | int              | 100     | Total number of epochs (full passes through dataset). |\n",
    "| time           | float            | None    | Max training time (hours). Overrides `epochs` if set. |\n",
    "| patience       | int              | 100     | Early stopping patience (epochs without improvement). |\n",
    "| batch          | int/float        | 16      | Batch size. Supports `int`, auto (`-1`), or fraction (e.g., `0.7`). |\n",
    "| imgsz          | int              | 640     | Target image size. Resizes to square images. |\n",
    "| save           | bool             | True    | Save training checkpoints and final weights. |\n",
    "| save_period    | int              | -1      | Save model checkpoints every N epochs. `-1` disables. |\n",
    "| cache          | bool             | False   | Cache dataset images (`ram`, `disk`, or `False`). |\n",
    "| device         | int/str/list     | None    | Training device(s): `0`, `[0,1]`, `cpu`, `mps`, `-1`. |\n",
    "| workers        | int              | 8       | Data loading workers per GPU rank. |\n",
    "| project        | str              | None    | Project directory for training outputs. |\n",
    "| name           | str              | None    | Name of run (subdir inside project). |\n",
    "| exist_ok       | bool             | False   | Allow overwriting of an existing `project/name`. |\n",
    "| pretrained     | bool/str         | True    | Use pretrained model (bool or path to weights). |\n",
    "| optimizer      | str              | auto    | Optimizer (`SGD`, `Adam`, `AdamW`, etc.). |\n",
    "| seed           | int              | 0       | Random seed for reproducibility. |\n",
    "| deterministic  | bool             | True    | Force deterministic algorithms (slower, reproducible). |\n",
    "| single_cls     | bool             | False   | Train all classes as one (binary classification). |\n",
    "| classes        | list[int]        | None    | Train only on specific class IDs. |\n",
    "| rect           | bool             | False   | Use rectangular batches (minimal padding). |\n",
    "| multi_scale    | bool             | False   | Train with variable image sizes. |\n",
    "| cos_lr         | bool             | False   | Cosine learning rate scheduler. |\n",
    "| close_mosaic   | int              | 10      | Disable mosaic augmentation for last N epochs. |\n",
    "| resume         | bool             | False   | Resume from last checkpoint. |\n",
    "| amp            | bool             | True    | Use Automatic Mixed Precision (faster, less memory). |\n",
    "| fraction       | float            | 1.0     | Fraction of dataset to use. |\n",
    "| profile        | bool             | False   | Profile ONNX/TensorRT speeds. |\n",
    "| freeze         | int/list         | None    | Freeze first N layers or list of layers. |\n",
    "| lr0            | float            | 0.01    | Initial learning rate. |\n",
    "| lrf            | float            | 0.01    | Final learning rate fraction. |\n",
    "| momentum       | float            | 0.937   | Momentum (SGD) / beta1 (Adam). |\n",
    "| weight_decay   | float            | 0.0005  | L2 regularization term. |\n",
    "| warmup_epochs  | float            | 3.0     | Warmup epochs for LR. |\n",
    "| warmup_momentum| float            | 0.8     | Warmup momentum start value. |\n",
    "| warmup_bias_lr | float            | 0.1     | Warmup bias learning rate. |\n",
    "| box            | float            | 7.5     | Weight for bounding box loss. |\n",
    "| cls            | float            | 0.5     | Weight for classification loss. |\n",
    "| dfl            | float            | 1.5     | Weight for distribution focal loss. |\n",
    "| pose           | float            | 12.0    | Weight for pose loss. |\n",
    "| kobj           | float            | 2.0     | Weight for keypoint objectness loss. |\n",
    "| nbs            | int              | 64      | Nominal batch size (loss normalization). |\n",
    "| overlap_mask   | bool             | True    | Merge object masks or keep separate. |\n",
    "| mask_ratio     | int              | 4       | Downsample ratio for segmentation masks. |\n",
    "| dropout        | float            | 0.0     | Dropout rate (classification). |\n",
    "| val            | bool             | True    | Enable validation during training. |\n",
    "| plots          | bool             | False   | Save plots of metrics and predictions. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8277a704",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2585166842.py, line 9)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mfraction=\"1.0\"--> float\u001b[39m\n                   ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Small Experimentation center\n",
    "\n",
    "model = YOLO(\"yolo11n-seg.yaml\") #train from scratch\n",
    "#model = YOLO(\"yolo11n-seg.pt\") # pretrained weights\n",
    "\n",
    "data=\"E:/Techlabs_AI/digital_wardrobe/eWardrobe/datasets/YOLOfull/YOLOfull.yaml\"\n",
    "#data=\"E:/Techlabs_AI/digital_wardrobe/eWardrobe/datasets/YOLOsmall/YOLOsmall.yaml\"\n",
    "\n",
    "pretrained=\"False\"\n",
    "project=\"E:/Techlabs_AI/digital_wardrobe/eWardrobe/YOLO/runs\"\n",
    "name=\"Run_full_yaml_pretrainFalse\"\n",
    "resume=\"False\"\n",
    "fraction=\"1.0\" #float\n",
    "epochs=10\n",
    "batch= -1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23f7accd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cu128\n",
      "12.8\n",
      "True\n",
      "NVIDIA GeForce RTX 4080\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)          # 2.7.1+cu128\n",
    "print(torch.version.cuda)         # 12.8\n",
    "print(torch.cuda.is_available())  # should be True\n",
    "print(torch.cuda.get_device_name(0))  # RTX 4080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c79212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.192 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.184  Python-3.12.10 torch-2.8.0+cu128 CUDA:0 (NVIDIA GeForce RTX 4080, 16376MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=E:/Techlabs_AI/digital_wardrobe/eWardrobe/datasets/YOLOfull/YOLOfull.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=E:/Techlabs_AI/digital_wardrobe/eWardrobe/YOLO/runs/Run_full_pt_pretrainTrue_continue6/weights/last.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=Run_full_pt_pretrainTrue_continue7, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=(True,), profile=False, project=E:/Techlabs_AI/digital_wardrobe/eWardrobe/YOLO/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=E:\\Techlabs_AI\\digital_wardrobe\\eWardrobe\\YOLO\\runs\\Run_full_pt_pretrainTrue_continue7, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    685975  ultralytics.nn.modules.head.Segment          [13, 32, 64, [64, 128, 256]]  \n",
      "YOLO11n-seg summary: 203 layers, 2,845,143 parameters, 2,845,127 gradients, 9.7 GFLOPs\n",
      "\n",
      "Transferred 561/561 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 585.3448.0 MB/s, size: 66.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning E:\\Techlabs_AI\\digital_wardrobe\\eWardrobe\\datasets\\YOLOfull\\train\\labels.cache... 191961 images, 0 backgrounds, 1 corrupt: 100%|██████████| 191961/191961 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mE:\\Techlabs_AI\\digital_wardrobe\\eWardrobe\\datasets\\YOLOfull\\train\\images\\164121.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.01068]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 132.938.4 MB/s, size: 49.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning E:\\Techlabs_AI\\digital_wardrobe\\eWardrobe\\datasets\\YOLOfull\\val\\labels.cache... 32153 images, 0 backgrounds, 0 corrupt: 100%|██████████| 32153/32153 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to E:\\Techlabs_AI\\digital_wardrobe\\eWardrobe\\YOLO\\runs\\Run_full_pt_pretrainTrue_continue7\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 90 weight(decay=0.0), 101 weight(decay=0.0005), 100 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mE:\\Techlabs_AI\\digital_wardrobe\\eWardrobe\\YOLO\\runs\\Run_full_pt_pretrainTrue_continue7\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20      2.81G     0.6043      2.132       0.85      1.005         34        640: 100%|██████████| 11998/11998 [33:55<00:00,  5.90it/s] \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1005/1005 [02:29<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      32153      52490      0.773      0.763      0.813      0.717      0.625      0.609      0.631      0.416\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20      4.52G     0.6213      2.166     0.8713      1.012         29        640: 100%|██████████| 11998/11998 [20:18<00:00,  9.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1005/1005 [02:27<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      32153      52490      0.773      0.755      0.815      0.718      0.625      0.604      0.632      0.416\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20      4.53G     0.6756      2.314     0.9705      1.042         26        640: 100%|██████████| 11998/11998 [19:40<00:00, 10.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1005/1005 [02:32<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      32153      52490      0.781      0.743       0.81      0.713       0.63      0.595      0.627      0.411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20      4.53G      0.711      2.422      1.041      1.063         39        640: 100%|██████████| 11998/11998 [20:18<00:00,  9.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1005/1005 [02:32<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      32153      52490       0.77      0.746      0.804      0.707      0.622      0.594      0.623      0.406\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20      4.53G     0.6964      2.392      1.016      1.055         36        640: 100%|██████████| 11998/11998 [20:04<00:00,  9.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1005/1005 [02:33<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      32153      52490      0.768      0.741      0.801      0.703      0.616       0.59      0.619      0.404\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20      4.53G     0.6852      2.366     0.9983      1.049         33        640: 100%|██████████| 11998/11998 [20:00<00:00,  9.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1005/1005 [02:33<00:00,  6.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      32153      52490      0.772      0.736        0.8      0.702      0.618      0.587      0.617      0.404\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20      4.53G     0.6763      2.335     0.9805      1.044         27        640: 100%|██████████| 11998/11998 [20:03<00:00,  9.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1005/1005 [02:32<00:00,  6.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      32153      52490      0.775      0.737        0.8      0.702      0.623      0.586      0.618      0.404\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20      4.53G     0.6698      2.316     0.9677       1.04         28        640: 100%|██████████| 11998/11998 [20:05<00:00,  9.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1005/1005 [02:31<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      32153      52490      0.775      0.738      0.802      0.704      0.624      0.586      0.619      0.405\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20      4.53G     0.6615      2.293     0.9514      1.035         32        640: 100%|██████████| 11998/11998 [19:59<00:00, 10.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1005/1005 [02:35<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      32153      52490      0.774      0.743      0.804      0.705      0.625      0.588      0.621      0.406\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20      4.53G     0.6547      2.279     0.9416      1.032         33        640: 100%|██████████| 11998/11998 [20:05<00:00,  9.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1005/1005 [02:32<00:00,  6.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      32153      52490      0.761      0.754      0.805      0.707      0.612      0.601      0.622      0.407\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/20      4.53G     0.5868      1.962     0.6836      1.015         15        640: 100%|██████████| 11998/11998 [19:54<00:00, 10.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1005/1005 [02:32<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      32153      52490      0.769      0.752      0.808      0.709      0.619      0.599      0.625      0.409\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/20      4.53G     0.5742      1.931      0.663      1.006         11        640: 100%|██████████| 11998/11998 [19:56<00:00, 10.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1005/1005 [02:32<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      32153      52490      0.775      0.749      0.809      0.711      0.624      0.598      0.626       0.41\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/20      4.53G     0.5647      1.901     0.6451     0.9987         15        640: 100%|██████████| 11998/11998 [19:47<00:00, 10.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1005/1005 [02:32<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      32153      52490      0.767       0.76      0.811      0.713      0.616      0.609      0.628      0.412\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/20      4.53G     0.5538      1.871     0.6282     0.9919         12        640: 100%|██████████| 11998/11998 [19:49<00:00, 10.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1005/1005 [02:31<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      32153      52490      0.772      0.759      0.813      0.717      0.623      0.606      0.631      0.415\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/20      4.54G      0.544      1.839     0.6101     0.9843         13        640: 100%|██████████| 11998/11998 [19:47<00:00, 10.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1005/1005 [02:30<00:00,  6.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      32153      52490      0.771      0.762      0.816       0.72       0.62       0.61      0.632      0.417\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/20      4.54G     0.5323      1.806     0.5899     0.9774         13        640: 100%|██████████| 11998/11998 [19:52<00:00, 10.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1005/1005 [02:31<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      32153      52490       0.77       0.77      0.817      0.722       0.62      0.615      0.634      0.419\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/20      4.54G     0.5202       1.77     0.5685     0.9691         14        640: 100%|██████████| 11998/11998 [19:49<00:00, 10.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1005/1005 [02:33<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      32153      52490      0.769      0.775       0.82      0.724      0.619       0.62      0.637      0.421\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/20      4.54G     0.5091      1.729     0.5464      0.962         13        640: 100%|██████████| 11998/11998 [19:48<00:00, 10.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1005/1005 [02:32<00:00,  6.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      32153      52490       0.78      0.767      0.822      0.727      0.627      0.615      0.638      0.423\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/20      4.54G     0.4966       1.69     0.5225     0.9544         14        640: 100%|██████████| 11998/11998 [19:46<00:00, 10.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1005/1005 [02:34<00:00,  6.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      32153      52490      0.783       0.77      0.823      0.729      0.631      0.616       0.64      0.424\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/20      4.54G     0.4845      1.643     0.4979     0.9465         12        640: 100%|██████████| 11998/11998 [19:52<00:00, 10.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1005/1005 [02:32<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      32153      52490       0.79      0.765      0.825      0.731      0.637      0.613      0.641      0.426\n",
      "\n",
      "20 epochs completed in 7.742 hours.\n",
      "Optimizer stripped from E:\\Techlabs_AI\\digital_wardrobe\\eWardrobe\\YOLO\\runs\\Run_full_pt_pretrainTrue_continue7\\weights\\last.pt, 6.0MB\n",
      "Optimizer stripped from E:\\Techlabs_AI\\digital_wardrobe\\eWardrobe\\YOLO\\runs\\Run_full_pt_pretrainTrue_continue7\\weights\\best.pt, 6.0MB\n",
      "\n",
      "Validating E:\\Techlabs_AI\\digital_wardrobe\\eWardrobe\\YOLO\\runs\\Run_full_pt_pretrainTrue_continue7\\weights\\best.pt...\n",
      "Ultralytics 8.3.184  Python-3.12.10 torch-2.8.0+cu128 CUDA:0 (NVIDIA GeForce RTX 4080, 16376MiB)\n",
      "YOLO11n-seg summary (fused): 113 layers, 2,837,103 parameters, 0 gradients, 9.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1005/1005 [02:17<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      32153      52490       0.79      0.765      0.825      0.731      0.636      0.613      0.641      0.426\n",
      "   short_sleeved_shirt      12371      12556       0.89      0.911      0.958      0.888      0.883      0.905      0.948      0.584\n",
      "    long_sleeved_shirt       5916       5966      0.797      0.845      0.892      0.806      0.777      0.828      0.859      0.433\n",
      " short_sleeved_outwear        142        142      0.637      0.346      0.467      0.396      0.598      0.325      0.383      0.165\n",
      "  long_sleeved_outwear       1999       2011      0.764      0.883      0.872      0.798      0.664      0.767       0.68      0.236\n",
      "                  vest       2098       2113      0.773      0.815      0.864      0.754      0.765      0.809      0.852      0.634\n",
      "                 sling        317        322      0.784       0.54      0.646      0.556      0.778      0.537      0.629      0.471\n",
      "                shorts       4133       4167      0.888      0.854       0.94      0.755     0.0189     0.0182     0.0052    0.00326\n",
      "              trousers       9494       9586      0.903      0.941      0.969      0.806      0.023      0.024    0.00804    0.00525\n",
      "                 skirt       6499       6522      0.852      0.859       0.92      0.806      0.835      0.844      0.872      0.732\n",
      "   short_sleeved_dress       3076       3127      0.784      0.777      0.845      0.784      0.776      0.771      0.832      0.595\n",
      "    long_sleeved_dress       1460       1477      0.617      0.666       0.68      0.624      0.606      0.658      0.655      0.408\n",
      "            vest_dress       3319       3352      0.775      0.791      0.856      0.786       0.76      0.777      0.821      0.683\n",
      "           sling_dress       1137       1149      0.805       0.72      0.812       0.74      0.787      0.709      0.782      0.582\n",
      "Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1mE:\\Techlabs_AI\\digital_wardrobe\\eWardrobe\\YOLO\\runs\\Run_full_pt_pretrainTrue_continue7\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# I used this to keep on training from the last.pt file\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "#model_cfg=\"yolo11s-seg.pt\"   # can be .yaml (architecture) or .pt (weights+arch)\n",
    "model_cfg= \"E:/Techlabs_AI/digital_wardrobe/eWardrobe/YOLO/runs/Run_full_pt_pretrainTrue_continue6/weights/last.pt\"\n",
    "data=\"E:/Techlabs_AI/digital_wardrobe/eWardrobe/datasets/YOLOfull/YOLOfull.yaml\"\n",
    "#data=\"E:/Techlabs_AI/digital_wardrobe/eWardrobe/datasets/YOLOsmall/YOLOsmall.yaml\",\n",
    "pretrained=True,               # bool or str (path to custom checkpoint)\n",
    "project=\"E:/Techlabs_AI/digital_wardrobe/eWardrobe/YOLO/runs\"\n",
    "name=\"Run_full_pt_pretrainTrue_continue7\"\n",
    "resume=False\n",
    "fraction=1\n",
    "epochs=20\n",
    "batch=16\n",
    "imgsz=640\n",
    "plots=True\n",
    "\n",
    "\"\"\"\n",
    "Experimentation center for YOLO training.\n",
    "\"\"\"\n",
    "# Initialize model\n",
    "model = YOLO(model_cfg)\n",
    "\n",
    "# Train\n",
    "results = model.train(\n",
    "    data=data,\n",
    "    pretrained=pretrained,\n",
    "    project=project,\n",
    "    name=name,\n",
    "    resume=resume,\n",
    "    fraction=fraction,\n",
    "    epochs=epochs,\n",
    "    batch=batch,\n",
    "    plots=plots,\n",
    "    imgsz=imgsz\n",
    ")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f03a03",
   "metadata": {},
   "source": [
    "YOLO11 can process different types of input sources for inference, as shown in the table below. The sources include static images, video streams, and various data formats. The table also indicates whether each source can be used in streaming mode with the argument stream=True ✅. Streaming mode is beneficial for processing videos or live streams as it creates a generator of results instead of loading all frames into memory.\n",
    "\n",
    "\n",
    "| Source        | Example                                   | Type         | Notes                                                                 |\n",
    "|---------------|-------------------------------------------|--------------|----------------------------------------------------------------------|\n",
    "| image         | `'image.jpg'`                             | str or Path  | Single image file.                                                    |\n",
    "| URL           | `'https://ultralytics.com/images/bus.jpg'`| str          | URL to an image.                                                      |\n",
    "| screenshot    | `'screen'`                                | str          | Capture a screenshot.                                                 |\n",
    "| PIL           | `Image.open('image.jpg')`                 | PIL.Image    | HWC format with RGB channels.                                         |\n",
    "| OpenCV        | `cv2.imread('image.jpg')`                 | np.ndarray   | HWC format with BGR channels uint8 (0-255).                           |\n",
    "| numpy         | `np.zeros((640,1280,3))`                  | np.ndarray   | HWC format with BGR channels uint8 (0-255).                           |\n",
    "| torch         | `torch.zeros(16,3,320,640)`               | torch.Tensor | BCHW format with RGB channels float32 (0.0-1.0).                      |\n",
    "| CSV           | `'sources.csv'`                           | str or Path  | CSV file containing paths to images, videos, or directories.          |\n",
    "| video ✅       | `'video.mp4'`                             | str or Path  | Video file in formats like MP4, AVI, etc.                             |\n",
    "| directory ✅   | `'path/'`                                 | str or Path  | Path to a directory containing images or videos.                      |\n",
    "| glob ✅        | `'path/*.jpg'`                            | str          | Glob pattern to match multiple files. Use the `*` as a wildcard.      |\n",
    "| YouTube ✅     | `'https://youtu.be/LNwODJXcvt4'`          | str          | URL to a YouTube video.                                               |\n",
    "| stream ✅      | `'rtsp://example.com/media.mp4'`          | str          | URL for streaming protocols (RTSP, RTMP, TCP) or IP address.          |\n",
    "| multi-stream ✅| `'list.streams'`                          | str or Path  | `.streams` text file with one stream URL per row (batch-size = count).|\n",
    "| webcam ✅      | `0`                                       | int          | Index of the connected camera device to run inference on.             |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9a2ac7",
   "metadata": {},
   "source": [
    "Inference arguments:\n",
    "\n",
    "| Argument       | Type        | Default                  | Description                                                                                                                                                   |\n",
    "|----------------|-------------|--------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| source         | str         | `'ultralytics/assets'`   | Data source for inference: image path, video file, directory, URL, or device ID (e.g., webcam). Supports many formats.                                        |\n",
    "| conf           | float       | 0.25                     | Minimum confidence threshold for detections. Detections below this value are discarded. Helps reduce false positives.                                          |\n",
    "| iou            | float       | 0.7                      | IoU threshold for Non-Maximum Suppression (NMS). Lower values remove more overlapping boxes, useful to reduce duplicates.                                      |\n",
    "| imgsz          | int/tuple   | 640                      | Image size for inference. Can be a single int (square resize) or a tuple `(h, w)`. Impacts speed vs. accuracy.                                                 |\n",
    "| rect           | bool        | True                     | If enabled: minimally pads shorter side for stride compatibility. If disabled: pads to a square.                                                              |\n",
    "| half           | bool        | False                    | Enables half-precision (FP16) inference. Speeds up inference on supported GPUs with minor accuracy tradeoff.                                                   |\n",
    "| device         | str         | None                     | Compute device: `\"cpu\"`, `\"cuda:0\"`, `\"0\"` (first GPU), etc.                                                                                                   |\n",
    "| batch          | int         | 1                        | Batch size for inference (only for directory, video, or `.txt` sources). Larger batch → higher throughput.                                                     |\n",
    "| max_det        | int         | 300                      | Maximum number of detections per image. Prevents too many boxes in dense scenes.                                                                               |\n",
    "| vid_stride     | int         | 1                        | Frame stride for video input. Higher values skip frames (faster but less temporal resolution).                                                                 |\n",
    "| stream_buffer  | bool        | False                    | If False: drops old frames for real-time speed. If True: buffers all frames (higher latency).                                                                  |\n",
    "| visualize      | bool        | False                    | Enables visualization of model features during inference. Helpful for debugging/model insights.                                                                |\n",
    "| augment        | bool        | False                    | Enables test-time augmentation (TTA). Improves robustness but slows inference.                                                                                 |\n",
    "| agnostic_nms   | bool        | False                    | Enables class-agnostic NMS (overlapping boxes merged across classes). Useful when class overlap occurs.                                                        |\n",
    "| classes        | list[int]   | None                     | Filters detections to specific class IDs only. Good for focusing on relevant classes in multi-class tasks.                                                     |\n",
    "| retina_masks   | bool        | False                    | Returns high-res segmentation masks (original image size). If False: masks are resized to inference size.                                                      |\n",
    "| embed          | list[int]   | None                     | Extracts feature vectors/embeddings from specific layers. Useful for clustering, similarity search, etc.                                                       |\n",
    "| project        | str         | None                     | Project directory name where prediction outputs are saved (if `save=True`).                                                                                   |\n",
    "| name           | str         | None                     | Subdirectory name within project folder for saving outputs (if `save=True`).                                                                                   |\n",
    "| stream         | bool        | False                    | Returns a generator of `Results` objects for long videos or many images. Saves memory.                                                                         |\n",
    "| verbose        | bool        | True                     | Controls logging verbosity. If True: detailed inference logs shown in terminal.                                                                                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47647f35",
   "metadata": {},
   "source": [
    "Visualization arguments:\n",
    "\n",
    "| Argument     | Type        | Default        | Description                                                                                                                                                                      |\n",
    "|--------------|-------------|----------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| show         | bool        | False          | If True, displays annotated images/videos in a window. Useful for immediate visual feedback during development or testing.                                                       |\n",
    "| save         | bool        | False / True   | Saves annotated images/videos to file. Defaults to **True in CLI**, **False in Python**. Useful for documentation, analysis, or sharing.                                         |\n",
    "| save_frames  | bool        | False          | When processing videos, saves individual frames as images. Helpful for extracting frames or frame-by-frame analysis.                                                             |\n",
    "| save_txt     | bool        | False          | Saves detection results in text format: `[class] [x_center] [y_center] [width] [height] [confidence]`. Useful for integration with other tools.                                  |\n",
    "| save_conf    | bool        | False          | Includes confidence scores in saved text files. Provides richer detail for post-processing and evaluation.                                                                       |\n",
    "| save_crop    | bool        | False          | Saves cropped images of detected objects. Useful for dataset creation, augmentation, or focused analysis.                                                                        |\n",
    "| show_labels  | bool        | True           | Displays labels for each detection in the visual output. Provides immediate understanding of detected objects.                                                                   |\n",
    "| show_conf    | bool        | True           | Displays confidence score next to each label in the visual output. Helps gauge model certainty.                                                                                  |\n",
    "| show_boxes   | bool        | True           | Draws bounding boxes around detected objects. Essential for visually locating objects in images/videos.                                                                          |\n",
    "| line_width   | None or int | None           | Sets bounding box line width. If `None`, auto-adjusts based on image size. Allows customization for clarity (e.g., thick lines for presentations, thin for dense detections).     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3828e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ultralytics predict sample code\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolo11n.pt\")  # pretrained YOLO11n model\n",
    "\n",
    "# Run batched inference on a list of images\n",
    "results = model([\"image1.jpg\", \"image2.jpg\"], stream=True)  # return a generator of Results objects\n",
    "\n",
    "# Process results generator\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
    "    result.show()  # display to screen\n",
    "    result.save(filename=\"result.jpg\")  # save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2d58d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 short_sleeved_dress, 1 vest_dress, 45.0ms\n",
      "\n",
      "🔹 Results for image 1:\n",
      "Boxes: ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([11.,  9.], device='cuda:0')\n",
      "conf: tensor([0.9044, 0.8369], device='cuda:0')\n",
      "data: tensor([[4.1167e+02, 5.7438e+02, 8.6664e+02, 1.3534e+03, 9.0440e-01, 1.1000e+01],\n",
      "        [1.2013e+03, 5.5796e+02, 1.7427e+03, 1.5355e+03, 8.3687e-01, 9.0000e+00]], device='cuda:0')\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1536, 2048)\n",
      "shape: torch.Size([2, 6])\n",
      "xywh: tensor([[ 639.1555,  963.8795,  454.9743,  778.9946],\n",
      "        [1471.9586, 1046.7344,  541.4116,  977.5525]], device='cuda:0')\n",
      "xywhn: tensor([[0.3121, 0.6275, 0.2222, 0.5072],\n",
      "        [0.7187, 0.6815, 0.2644, 0.6364]], device='cuda:0')\n",
      "xyxy: tensor([[ 411.6684,  574.3823,  866.6427, 1353.3768],\n",
      "        [1201.2528,  557.9581, 1742.6644, 1535.5106]], device='cuda:0')\n",
      "xyxyn: tensor([[0.2010, 0.3739, 0.4232, 0.8811],\n",
      "        [0.5865, 0.3633, 0.8509, 0.9997]], device='cuda:0')\n",
      "Masks: ultralytics.engine.results.Masks object with attributes:\n",
      "\n",
      "data: tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0')\n",
      "orig_shape: (1536, 2048)\n",
      "shape: torch.Size([2, 480, 640])\n",
      "xy: [array([[      675.2,       569.6],\n",
      "       [      675.2,       579.2],\n",
      "       [      646.4,         608],\n",
      "       [      643.2,         608],\n",
      "       [        640,       611.2],\n",
      "       [      636.8,       611.2],\n",
      "       [      633.6,       614.4],\n",
      "       [      630.4,       614.4],\n",
      "       [      627.2,       617.6],\n",
      "       [        624,       617.6],\n",
      "       [      620.8,       620.8],\n",
      "       [      614.4,       620.8],\n",
      "       [      611.2,         624],\n",
      "       [      604.8,         624],\n",
      "       [      601.6,       627.2],\n",
      "       [        544,       627.2],\n",
      "       [      540.8,         624],\n",
      "       [      534.4,         624],\n",
      "       [      521.6,       611.2],\n",
      "       [      518.4,       611.2],\n",
      "       [      508.8,       601.6],\n",
      "       [      499.2,       601.6],\n",
      "       [        496,       604.8],\n",
      "       [      486.4,       604.8],\n",
      "       [      483.2,         608],\n",
      "       [        480,         608],\n",
      "       [      476.8,       611.2],\n",
      "       [      473.6,       611.2],\n",
      "       [      467.2,       617.6],\n",
      "       [        464,       617.6],\n",
      "       [      460.8,       620.8],\n",
      "       [      457.6,       620.8],\n",
      "       [      454.4,         624],\n",
      "       [      451.2,         624],\n",
      "       [        448,       627.2],\n",
      "       [      444.8,       627.2],\n",
      "       [      441.6,       630.4],\n",
      "       [      438.4,       630.4],\n",
      "       [      435.2,       633.6],\n",
      "       [        432,       633.6],\n",
      "       [      428.8,       636.8],\n",
      "       [        416,       636.8],\n",
      "       [        416,         688],\n",
      "       [      428.8,         688],\n",
      "       [      441.6,       700.8],\n",
      "       [      441.6,         704],\n",
      "       [        448,       710.4],\n",
      "       [        448,       713.6],\n",
      "       [      451.2,       716.8],\n",
      "       [      451.2,         720],\n",
      "       [      454.4,       723.2],\n",
      "       [      454.4,       729.6],\n",
      "       [      457.6,       732.8],\n",
      "       [      457.6,         736],\n",
      "       [      460.8,       739.2],\n",
      "       [      460.8,       745.6],\n",
      "       [        464,       748.8],\n",
      "       [        464,         752],\n",
      "       [      467.2,       755.2],\n",
      "       [      467.2,       761.6],\n",
      "       [      470.4,       764.8],\n",
      "       [      470.4,       777.6],\n",
      "       [      473.6,       780.8],\n",
      "       [      473.6,       793.6],\n",
      "       [      476.8,       796.8],\n",
      "       [      476.8,       812.8],\n",
      "       [        480,         816],\n",
      "       [        480,       828.8],\n",
      "       [      483.2,         832],\n",
      "       [      483.2,       841.6],\n",
      "       [      486.4,       844.8],\n",
      "       [      486.4,       857.6],\n",
      "       [      489.6,       860.8],\n",
      "       [      489.6,       873.6],\n",
      "       [      492.8,       876.8],\n",
      "       [      492.8,         896],\n",
      "       [        496,       899.2],\n",
      "       [        496,       915.2],\n",
      "       [      492.8,       918.4],\n",
      "       [      492.8,       953.6],\n",
      "       [      489.6,       956.8],\n",
      "       [      489.6,       969.6],\n",
      "       [      486.4,       972.8],\n",
      "       [      486.4,         992],\n",
      "       [      483.2,       995.2],\n",
      "       [      483.2,      1014.4],\n",
      "       [        480,      1017.6],\n",
      "       [        480,      1036.8],\n",
      "       [      476.8,        1040],\n",
      "       [      476.8,      1052.8],\n",
      "       [      473.6,        1056],\n",
      "       [      473.6,      1065.6],\n",
      "       [      470.4,      1068.8],\n",
      "       [      470.4,      1084.8],\n",
      "       [      467.2,        1088],\n",
      "       [      467.2,      1107.2],\n",
      "       [        464,      1110.4],\n",
      "       [        464,      1129.6],\n",
      "       [      460.8,      1132.8],\n",
      "       [      460.8,        1152],\n",
      "       [      457.6,      1155.2],\n",
      "       [      457.6,      1187.2],\n",
      "       [      454.4,      1190.4],\n",
      "       [      454.4,      1203.2],\n",
      "       [      451.2,      1206.4],\n",
      "       [      451.2,      1276.8],\n",
      "       [        448,        1280],\n",
      "       [        448,      1305.6],\n",
      "       [      451.2,      1308.8],\n",
      "       [      451.2,        1312],\n",
      "       [      454.4,      1315.2],\n",
      "       [      457.6,      1315.2],\n",
      "       [      460.8,      1318.4],\n",
      "       [        464,      1318.4],\n",
      "       [      467.2,      1321.6],\n",
      "       [      470.4,      1321.6],\n",
      "       [      473.6,      1324.8],\n",
      "       [      476.8,      1324.8],\n",
      "       [        480,        1328],\n",
      "       [      483.2,        1328],\n",
      "       [      499.2,        1344],\n",
      "       [      499.2,      1347.2],\n",
      "       [      502.4,      1350.4],\n",
      "       [      502.4,        1360],\n",
      "       [      627.2,        1360],\n",
      "       [      627.2,      1350.4],\n",
      "       [      630.4,      1347.2],\n",
      "       [      636.8,      1347.2],\n",
      "       [        640,      1350.4],\n",
      "       [        640,        1360],\n",
      "       [      643.2,        1360],\n",
      "       [      643.2,      1350.4],\n",
      "       [      646.4,      1347.2],\n",
      "       [        656,      1347.2],\n",
      "       [      659.2,        1344],\n",
      "       [        672,        1344],\n",
      "       [      675.2,      1340.8],\n",
      "       [      684.8,      1340.8],\n",
      "       [        688,      1337.6],\n",
      "       [      691.2,      1337.6],\n",
      "       [      694.4,      1334.4],\n",
      "       [      700.8,      1334.4],\n",
      "       [        704,      1331.2],\n",
      "       [      710.4,      1331.2],\n",
      "       [      713.6,        1328],\n",
      "       [      716.8,        1328],\n",
      "       [        720,      1324.8],\n",
      "       [      723.2,      1324.8],\n",
      "       [      726.4,      1321.6],\n",
      "       [      729.6,      1321.6],\n",
      "       [      732.8,      1318.4],\n",
      "       [      739.2,      1318.4],\n",
      "       [      742.4,      1315.2],\n",
      "       [      745.6,      1315.2],\n",
      "       [      748.8,        1312],\n",
      "       [        752,        1312],\n",
      "       [      758.4,      1305.6],\n",
      "       [      761.6,      1305.6],\n",
      "       [      764.8,      1302.4],\n",
      "       [        768,      1302.4],\n",
      "       [      771.2,      1299.2],\n",
      "       [      774.4,      1299.2],\n",
      "       [      780.8,      1292.8],\n",
      "       [        784,      1292.8],\n",
      "       [      787.2,      1289.6],\n",
      "       [      793.6,      1289.6],\n",
      "       [      796.8,      1286.4],\n",
      "       [        800,      1286.4],\n",
      "       [      806.4,        1280],\n",
      "       [      809.6,        1280],\n",
      "       [      812.8,      1276.8],\n",
      "       [        816,      1276.8],\n",
      "       [      822.4,      1270.4],\n",
      "       [      825.6,      1270.4],\n",
      "       [        832,        1264],\n",
      "       [      835.2,        1264],\n",
      "       [      838.4,      1260.8],\n",
      "       [      844.8,      1260.8],\n",
      "       [        848,      1257.6],\n",
      "       [      851.2,      1257.6],\n",
      "       [      860.8,        1248],\n",
      "       [      873.6,        1248],\n",
      "       [      873.6,      1225.6],\n",
      "       [        864,      1225.6],\n",
      "       [      860.8,      1222.4],\n",
      "       [      860.8,      1219.2],\n",
      "       [      857.6,        1216],\n",
      "       [      857.6,      1203.2],\n",
      "       [      854.4,        1200],\n",
      "       [      854.4,      1180.8],\n",
      "       [      851.2,      1177.6],\n",
      "       [      851.2,      1155.2],\n",
      "       [        848,        1152],\n",
      "       [        848,      1139.2],\n",
      "       [      844.8,        1136],\n",
      "       [      844.8,      1126.4],\n",
      "       [      841.6,      1123.2],\n",
      "       [      841.6,      1113.6],\n",
      "       [      838.4,      1110.4],\n",
      "       [      838.4,      1097.6],\n",
      "       [      835.2,      1094.4],\n",
      "       [      835.2,      1081.6],\n",
      "       [        832,      1078.4],\n",
      "       [        832,      1068.8],\n",
      "       [      828.8,      1065.6],\n",
      "       [      828.8,      1059.2],\n",
      "       [      825.6,        1056],\n",
      "       [      825.6,      1046.4],\n",
      "       [      822.4,      1043.2],\n",
      "       [      822.4,      1036.8],\n",
      "       [      819.2,      1033.6],\n",
      "       [      819.2,      1027.2],\n",
      "       [        816,        1024],\n",
      "       [        816,      1017.6],\n",
      "       [      812.8,      1014.4],\n",
      "       [      812.8,      1011.2],\n",
      "       [      809.6,        1008],\n",
      "       [      809.6,      1001.6],\n",
      "       [      806.4,       998.4],\n",
      "       [      806.4,       988.8],\n",
      "       [      803.2,       985.6],\n",
      "       [      803.2,       979.2],\n",
      "       [        800,         976],\n",
      "       [        800,       969.6],\n",
      "       [      796.8,       966.4],\n",
      "       [      796.8,         960],\n",
      "       [      793.6,       956.8],\n",
      "       [      793.6,       950.4],\n",
      "       [      790.4,       947.2],\n",
      "       [      790.4,       940.8],\n",
      "       [      787.2,       937.6],\n",
      "       [      787.2,       931.2],\n",
      "       [        784,         928],\n",
      "       [        784,       924.8],\n",
      "       [      780.8,       921.6],\n",
      "       [      780.8,       918.4],\n",
      "       [      777.6,       915.2],\n",
      "       [      777.6,       908.8],\n",
      "       [      774.4,       905.6],\n",
      "       [      774.4,         896],\n",
      "       [      771.2,       892.8],\n",
      "       [      771.2,       886.4],\n",
      "       [        768,       883.2],\n",
      "       [        768,       873.6],\n",
      "       [      764.8,       870.4],\n",
      "       [      764.8,       860.8],\n",
      "       [      761.6,       857.6],\n",
      "       [      761.6,       841.6],\n",
      "       [      758.4,       838.4],\n",
      "       [      758.4,       812.8],\n",
      "       [      755.2,       809.6],\n",
      "       [      755.2,       764.8],\n",
      "       [      758.4,       761.6],\n",
      "       [      758.4,       726.4],\n",
      "       [      755.2,       723.2],\n",
      "       [      755.2,       684.8],\n",
      "       [        752,       681.6],\n",
      "       [        752,         640],\n",
      "       [      755.2,       636.8],\n",
      "       [      755.2,         624],\n",
      "       [        752,       620.8],\n",
      "       [        752,       617.6],\n",
      "       [      755.2,       614.4],\n",
      "       [      755.2,       569.6]], dtype=float32), array([[     1340.8,       556.8],\n",
      "       [     1340.8,         576],\n",
      "       [       1344,       579.2],\n",
      "       [       1344,       582.4],\n",
      "       [     1340.8,       585.6],\n",
      "       [     1340.8,       595.2],\n",
      "       [     1337.6,       598.4],\n",
      "       [     1337.6,         608],\n",
      "       [     1334.4,       611.2],\n",
      "       [     1334.4,       652.8],\n",
      "       [     1331.2,         656],\n",
      "       [     1331.2,       700.8],\n",
      "       [     1334.4,         704],\n",
      "       [     1334.4,       726.4],\n",
      "       [     1331.2,       729.6],\n",
      "       [     1331.2,       739.2],\n",
      "       [       1328,       742.4],\n",
      "       [       1328,         848],\n",
      "       [     1324.8,       851.2],\n",
      "       [     1324.8,         864],\n",
      "       [     1321.6,       867.2],\n",
      "       [     1321.6,       873.6],\n",
      "       [     1318.4,       876.8],\n",
      "       [     1318.4,       886.4],\n",
      "       [     1315.2,       889.6],\n",
      "       [     1315.2,       892.8],\n",
      "       [       1312,         896],\n",
      "       [       1312,       905.6],\n",
      "       [     1308.8,       908.8],\n",
      "       [     1308.8,       915.2],\n",
      "       [     1305.6,       918.4],\n",
      "       [     1305.6,       924.8],\n",
      "       [     1302.4,         928],\n",
      "       [     1302.4,       947.2],\n",
      "       [     1299.2,       950.4],\n",
      "       [     1299.2,       963.2],\n",
      "       [       1296,       966.4],\n",
      "       [       1296,       969.6],\n",
      "       [     1292.8,       972.8],\n",
      "       [     1292.8,         976],\n",
      "       [     1289.6,       979.2],\n",
      "       [     1289.6,       982.4],\n",
      "       [     1286.4,       985.6],\n",
      "       [     1286.4,         992],\n",
      "       [     1283.2,       995.2],\n",
      "       [     1283.2,      1001.6],\n",
      "       [       1280,      1004.8],\n",
      "       [       1280,      1043.2],\n",
      "       [     1276.8,      1046.4],\n",
      "       [     1276.8,      1068.8],\n",
      "       [     1273.6,        1072],\n",
      "       [     1273.6,      1078.4],\n",
      "       [     1270.4,      1081.6],\n",
      "       [     1270.4,        1088],\n",
      "       [     1267.2,      1091.2],\n",
      "       [     1267.2,      1094.4],\n",
      "       [       1264,      1097.6],\n",
      "       [       1264,      1100.8],\n",
      "       [     1251.2,      1113.6],\n",
      "       [       1248,      1113.6],\n",
      "       [       1248,      1116.8],\n",
      "       [     1244.8,        1120],\n",
      "       [     1244.8,      1155.2],\n",
      "       [     1241.6,      1158.4],\n",
      "       [     1241.6,      1177.6],\n",
      "       [     1238.4,      1180.8],\n",
      "       [     1238.4,      1219.2],\n",
      "       [     1235.2,      1222.4],\n",
      "       [     1235.2,      1235.2],\n",
      "       [       1232,      1238.4],\n",
      "       [       1232,      1241.6],\n",
      "       [     1228.8,      1244.8],\n",
      "       [     1228.8,      1251.2],\n",
      "       [     1225.6,      1254.4],\n",
      "       [     1225.6,      1270.4],\n",
      "       [     1222.4,      1273.6],\n",
      "       [     1222.4,      1289.6],\n",
      "       [     1219.2,      1292.8],\n",
      "       [     1219.2,      1308.8],\n",
      "       [       1216,        1312],\n",
      "       [       1216,      1315.2],\n",
      "       [     1212.8,      1318.4],\n",
      "       [     1212.8,      1324.8],\n",
      "       [     1209.6,        1328],\n",
      "       [     1209.6,      1334.4],\n",
      "       [     1212.8,      1337.6],\n",
      "       [     1212.8,      1340.8],\n",
      "       [     1219.2,      1347.2],\n",
      "       [     1219.2,      1366.4],\n",
      "       [       1216,      1369.6],\n",
      "       [       1216,      1385.6],\n",
      "       [     1212.8,      1388.8],\n",
      "       [     1212.8,        1392],\n",
      "       [     1209.6,      1395.2],\n",
      "       [     1196.8,      1395.2],\n",
      "       [     1196.8,        1520],\n",
      "       [     1209.6,        1520],\n",
      "       [     1219.2,      1529.6],\n",
      "       [     1219.2,      1532.8],\n",
      "       [     1235.2,      1532.8],\n",
      "       [     1235.2,      1529.6],\n",
      "       [     1238.4,      1526.4],\n",
      "       [     1254.4,      1526.4],\n",
      "       [     1257.6,      1529.6],\n",
      "       [     1257.6,      1532.8],\n",
      "       [       1664,      1532.8],\n",
      "       [       1664,      1516.8],\n",
      "       [     1667.2,      1513.6],\n",
      "       [       1664,      1510.4],\n",
      "       [       1664,      1459.2],\n",
      "       [     1660.8,        1456],\n",
      "       [     1660.8,      1433.6],\n",
      "       [       1664,      1430.4],\n",
      "       [       1664,        1424],\n",
      "       [     1660.8,      1420.8],\n",
      "       [     1660.8,      1347.2],\n",
      "       [     1657.6,        1344],\n",
      "       [     1657.6,      1331.2],\n",
      "       [     1654.4,        1328],\n",
      "       [     1654.4,      1321.6],\n",
      "       [     1657.6,      1318.4],\n",
      "       [     1657.6,        1312],\n",
      "       [     1660.8,      1308.8],\n",
      "       [     1660.8,        1296],\n",
      "       [     1657.6,      1292.8],\n",
      "       [     1657.6,      1267.2],\n",
      "       [     1660.8,        1264],\n",
      "       [     1660.8,      1251.2],\n",
      "       [     1657.6,        1248],\n",
      "       [     1657.6,      1238.4],\n",
      "       [     1654.4,      1235.2],\n",
      "       [     1654.4,      1222.4],\n",
      "       [     1651.2,      1219.2],\n",
      "       [     1651.2,        1216],\n",
      "       [       1648,      1212.8],\n",
      "       [       1648,      1187.2],\n",
      "       [     1651.2,        1184],\n",
      "       [     1651.2,        1136],\n",
      "       [     1654.4,      1132.8],\n",
      "       [     1654.4,      1129.6],\n",
      "       [     1651.2,      1126.4],\n",
      "       [     1651.2,      1097.6],\n",
      "       [       1648,      1094.4],\n",
      "       [       1648,      1065.6],\n",
      "       [     1644.8,      1062.4],\n",
      "       [     1644.8,      1052.8],\n",
      "       [     1641.6,      1049.6],\n",
      "       [     1641.6,      1043.2],\n",
      "       [     1638.4,        1040],\n",
      "       [     1638.4,      1036.8],\n",
      "       [       1632,      1030.4],\n",
      "       [       1632,      1014.4],\n",
      "       [     1628.8,      1011.2],\n",
      "       [     1628.8,       988.8],\n",
      "       [     1625.6,       985.6],\n",
      "       [     1625.6,       966.4],\n",
      "       [     1622.4,       963.2],\n",
      "       [     1622.4,       870.4],\n",
      "       [     1625.6,       867.2],\n",
      "       [     1625.6,       857.6],\n",
      "       [     1628.8,       854.4],\n",
      "       [     1628.8,       828.8],\n",
      "       [       1632,       825.6],\n",
      "       [       1632,       796.8],\n",
      "       [     1635.2,       793.6],\n",
      "       [     1635.2,       777.6],\n",
      "       [     1638.4,       774.4],\n",
      "       [     1638.4,       764.8],\n",
      "       [     1641.6,       761.6],\n",
      "       [     1641.6,       755.2],\n",
      "       [     1644.8,         752],\n",
      "       [     1644.8,       729.6],\n",
      "       [       1648,       726.4],\n",
      "       [       1648,       713.6],\n",
      "       [     1651.2,       710.4],\n",
      "       [     1651.2,         704],\n",
      "       [     1654.4,       700.8],\n",
      "       [     1654.4,       694.4],\n",
      "       [     1657.6,       691.2],\n",
      "       [     1657.6,         688],\n",
      "       [     1660.8,       684.8],\n",
      "       [     1660.8,       681.6],\n",
      "       [       1664,       678.4],\n",
      "       [       1664,         672],\n",
      "       [     1667.2,       668.8],\n",
      "       [     1667.2,       662.4],\n",
      "       [     1670.4,       659.2],\n",
      "       [     1670.4,       652.8],\n",
      "       [     1673.6,       649.6],\n",
      "       [     1673.6,       646.4],\n",
      "       [     1676.8,       643.2],\n",
      "       [     1676.8,       636.8],\n",
      "       [       1680,       633.6],\n",
      "       [       1680,       630.4],\n",
      "       [     1689.6,       620.8],\n",
      "       [     1686.4,       617.6],\n",
      "       [     1686.4,       614.4],\n",
      "       [       1680,         608],\n",
      "       [     1676.8,         608],\n",
      "       [     1673.6,       604.8],\n",
      "       [     1670.4,       604.8],\n",
      "       [       1664,       598.4],\n",
      "       [     1660.8,       598.4],\n",
      "       [     1657.6,       595.2],\n",
      "       [     1654.4,       595.2],\n",
      "       [     1651.2,         592],\n",
      "       [     1644.8,         592],\n",
      "       [     1641.6,       588.8],\n",
      "       [     1638.4,       588.8],\n",
      "       [     1635.2,       585.6],\n",
      "       [     1628.8,       585.6],\n",
      "       [     1625.6,       582.4],\n",
      "       [     1622.4,       582.4],\n",
      "       [     1619.2,       579.2],\n",
      "       [       1584,       579.2],\n",
      "       [     1539.2,         624],\n",
      "       [       1536,         624],\n",
      "       [     1529.6,       630.4],\n",
      "       [     1526.4,       630.4],\n",
      "       [       1520,       636.8],\n",
      "       [     1516.8,       636.8],\n",
      "       [     1478.4,       675.2],\n",
      "       [       1456,       675.2],\n",
      "       [     1446.4,       665.6],\n",
      "       [     1446.4,       662.4],\n",
      "       [     1443.2,       659.2],\n",
      "       [     1443.2,         656],\n",
      "       [       1440,       652.8],\n",
      "       [       1440,       649.6],\n",
      "       [     1436.8,       646.4],\n",
      "       [     1436.8,         640],\n",
      "       [     1433.6,       636.8],\n",
      "       [     1433.6,       633.6],\n",
      "       [     1430.4,       630.4],\n",
      "       [     1430.4,       627.2],\n",
      "       [       1424,       620.8],\n",
      "       [       1424,       617.6],\n",
      "       [     1420.8,       614.4],\n",
      "       [     1420.8,       611.2],\n",
      "       [     1417.6,         608],\n",
      "       [     1417.6,       604.8],\n",
      "       [     1414.4,       601.6],\n",
      "       [     1414.4,       595.2],\n",
      "       [     1411.2,         592],\n",
      "       [     1411.2,       588.8],\n",
      "       [       1408,       585.6],\n",
      "       [       1408,       582.4],\n",
      "       [     1404.8,       579.2],\n",
      "       [     1404.8,       572.8],\n",
      "       [     1401.6,       569.6],\n",
      "       [     1401.6,       556.8]], dtype=float32)]\n",
      "xyn: [array([[    0.32969,     0.37083],\n",
      "       [    0.32969,     0.37708],\n",
      "       [    0.31563,     0.39583],\n",
      "       [    0.31406,     0.39583],\n",
      "       [     0.3125,     0.39792],\n",
      "       [    0.31094,     0.39792],\n",
      "       [    0.30937,         0.4],\n",
      "       [    0.30781,         0.4],\n",
      "       [    0.30625,     0.40208],\n",
      "       [    0.30469,     0.40208],\n",
      "       [    0.30312,     0.40417],\n",
      "       [        0.3,     0.40417],\n",
      "       [    0.29844,     0.40625],\n",
      "       [    0.29531,     0.40625],\n",
      "       [    0.29375,     0.40833],\n",
      "       [    0.26562,     0.40833],\n",
      "       [    0.26406,     0.40625],\n",
      "       [    0.26094,     0.40625],\n",
      "       [    0.25469,     0.39792],\n",
      "       [    0.25313,     0.39792],\n",
      "       [    0.24844,     0.39167],\n",
      "       [    0.24375,     0.39167],\n",
      "       [    0.24219,     0.39375],\n",
      "       [     0.2375,     0.39375],\n",
      "       [    0.23594,     0.39583],\n",
      "       [    0.23438,     0.39583],\n",
      "       [    0.23281,     0.39792],\n",
      "       [    0.23125,     0.39792],\n",
      "       [    0.22813,     0.40208],\n",
      "       [    0.22656,     0.40208],\n",
      "       [      0.225,     0.40417],\n",
      "       [    0.22344,     0.40417],\n",
      "       [    0.22187,     0.40625],\n",
      "       [    0.22031,     0.40625],\n",
      "       [    0.21875,     0.40833],\n",
      "       [    0.21719,     0.40833],\n",
      "       [    0.21563,     0.41042],\n",
      "       [    0.21406,     0.41042],\n",
      "       [     0.2125,      0.4125],\n",
      "       [    0.21094,      0.4125],\n",
      "       [    0.20937,     0.41458],\n",
      "       [    0.20312,     0.41458],\n",
      "       [    0.20312,     0.44792],\n",
      "       [    0.20937,     0.44792],\n",
      "       [    0.21563,     0.45625],\n",
      "       [    0.21563,     0.45833],\n",
      "       [    0.21875,      0.4625],\n",
      "       [    0.21875,     0.46458],\n",
      "       [    0.22031,     0.46667],\n",
      "       [    0.22031,     0.46875],\n",
      "       [    0.22187,     0.47083],\n",
      "       [    0.22187,       0.475],\n",
      "       [    0.22344,     0.47708],\n",
      "       [    0.22344,     0.47917],\n",
      "       [      0.225,     0.48125],\n",
      "       [      0.225,     0.48542],\n",
      "       [    0.22656,      0.4875],\n",
      "       [    0.22656,     0.48958],\n",
      "       [    0.22813,     0.49167],\n",
      "       [    0.22813,     0.49583],\n",
      "       [    0.22969,     0.49792],\n",
      "       [    0.22969,     0.50625],\n",
      "       [    0.23125,     0.50833],\n",
      "       [    0.23125,     0.51667],\n",
      "       [    0.23281,     0.51875],\n",
      "       [    0.23281,     0.52917],\n",
      "       [    0.23438,     0.53125],\n",
      "       [    0.23438,     0.53958],\n",
      "       [    0.23594,     0.54167],\n",
      "       [    0.23594,     0.54792],\n",
      "       [     0.2375,        0.55],\n",
      "       [     0.2375,     0.55833],\n",
      "       [    0.23906,     0.56042],\n",
      "       [    0.23906,     0.56875],\n",
      "       [    0.24062,     0.57083],\n",
      "       [    0.24062,     0.58333],\n",
      "       [    0.24219,     0.58542],\n",
      "       [    0.24219,     0.59583],\n",
      "       [    0.24062,     0.59792],\n",
      "       [    0.24062,     0.62083],\n",
      "       [    0.23906,     0.62292],\n",
      "       [    0.23906,     0.63125],\n",
      "       [     0.2375,     0.63333],\n",
      "       [     0.2375,     0.64583],\n",
      "       [    0.23594,     0.64792],\n",
      "       [    0.23594,     0.66042],\n",
      "       [    0.23438,      0.6625],\n",
      "       [    0.23438,       0.675],\n",
      "       [    0.23281,     0.67708],\n",
      "       [    0.23281,     0.68542],\n",
      "       [    0.23125,      0.6875],\n",
      "       [    0.23125,     0.69375],\n",
      "       [    0.22969,     0.69583],\n",
      "       [    0.22969,     0.70625],\n",
      "       [    0.22813,     0.70833],\n",
      "       [    0.22813,     0.72083],\n",
      "       [    0.22656,     0.72292],\n",
      "       [    0.22656,     0.73542],\n",
      "       [      0.225,      0.7375],\n",
      "       [      0.225,        0.75],\n",
      "       [    0.22344,     0.75208],\n",
      "       [    0.22344,     0.77292],\n",
      "       [    0.22187,       0.775],\n",
      "       [    0.22187,     0.78333],\n",
      "       [    0.22031,     0.78542],\n",
      "       [    0.22031,     0.83125],\n",
      "       [    0.21875,     0.83333],\n",
      "       [    0.21875,        0.85],\n",
      "       [    0.22031,     0.85208],\n",
      "       [    0.22031,     0.85417],\n",
      "       [    0.22187,     0.85625],\n",
      "       [    0.22344,     0.85625],\n",
      "       [      0.225,     0.85833],\n",
      "       [    0.22656,     0.85833],\n",
      "       [    0.22813,     0.86042],\n",
      "       [    0.22969,     0.86042],\n",
      "       [    0.23125,      0.8625],\n",
      "       [    0.23281,      0.8625],\n",
      "       [    0.23438,     0.86458],\n",
      "       [    0.23594,     0.86458],\n",
      "       [    0.24375,       0.875],\n",
      "       [    0.24375,     0.87708],\n",
      "       [    0.24531,     0.87917],\n",
      "       [    0.24531,     0.88542],\n",
      "       [    0.30625,     0.88542],\n",
      "       [    0.30625,     0.87917],\n",
      "       [    0.30781,     0.87708],\n",
      "       [    0.31094,     0.87708],\n",
      "       [     0.3125,     0.87917],\n",
      "       [     0.3125,     0.88542],\n",
      "       [    0.31406,     0.88542],\n",
      "       [    0.31406,     0.87917],\n",
      "       [    0.31563,     0.87708],\n",
      "       [    0.32031,     0.87708],\n",
      "       [    0.32188,       0.875],\n",
      "       [    0.32812,       0.875],\n",
      "       [    0.32969,     0.87292],\n",
      "       [    0.33437,     0.87292],\n",
      "       [    0.33594,     0.87083],\n",
      "       [     0.3375,     0.87083],\n",
      "       [    0.33906,     0.86875],\n",
      "       [    0.34219,     0.86875],\n",
      "       [    0.34375,     0.86667],\n",
      "       [    0.34688,     0.86667],\n",
      "       [    0.34844,     0.86458],\n",
      "       [       0.35,     0.86458],\n",
      "       [    0.35156,      0.8625],\n",
      "       [    0.35313,      0.8625],\n",
      "       [    0.35469,     0.86042],\n",
      "       [    0.35625,     0.86042],\n",
      "       [    0.35781,     0.85833],\n",
      "       [    0.36094,     0.85833],\n",
      "       [     0.3625,     0.85625],\n",
      "       [    0.36406,     0.85625],\n",
      "       [    0.36562,     0.85417],\n",
      "       [    0.36719,     0.85417],\n",
      "       [    0.37031,        0.85],\n",
      "       [    0.37187,        0.85],\n",
      "       [    0.37344,     0.84792],\n",
      "       [      0.375,     0.84792],\n",
      "       [    0.37656,     0.84583],\n",
      "       [    0.37813,     0.84583],\n",
      "       [    0.38125,     0.84167],\n",
      "       [    0.38281,     0.84167],\n",
      "       [    0.38438,     0.83958],\n",
      "       [     0.3875,     0.83958],\n",
      "       [    0.38906,      0.8375],\n",
      "       [    0.39062,      0.8375],\n",
      "       [    0.39375,     0.83333],\n",
      "       [    0.39531,     0.83333],\n",
      "       [    0.39687,     0.83125],\n",
      "       [    0.39844,     0.83125],\n",
      "       [    0.40156,     0.82708],\n",
      "       [    0.40312,     0.82708],\n",
      "       [    0.40625,     0.82292],\n",
      "       [    0.40781,     0.82292],\n",
      "       [    0.40938,     0.82083],\n",
      "       [     0.4125,     0.82083],\n",
      "       [    0.41406,     0.81875],\n",
      "       [    0.41563,     0.81875],\n",
      "       [    0.42031,      0.8125],\n",
      "       [    0.42656,      0.8125],\n",
      "       [    0.42656,     0.79792],\n",
      "       [    0.42188,     0.79792],\n",
      "       [    0.42031,     0.79583],\n",
      "       [    0.42031,     0.79375],\n",
      "       [    0.41875,     0.79167],\n",
      "       [    0.41875,     0.78333],\n",
      "       [    0.41719,     0.78125],\n",
      "       [    0.41719,     0.76875],\n",
      "       [    0.41563,     0.76667],\n",
      "       [    0.41563,     0.75208],\n",
      "       [    0.41406,        0.75],\n",
      "       [    0.41406,     0.74167],\n",
      "       [     0.4125,     0.73958],\n",
      "       [     0.4125,     0.73333],\n",
      "       [    0.41094,     0.73125],\n",
      "       [    0.41094,       0.725],\n",
      "       [    0.40938,     0.72292],\n",
      "       [    0.40938,     0.71458],\n",
      "       [    0.40781,      0.7125],\n",
      "       [    0.40781,     0.70417],\n",
      "       [    0.40625,     0.70208],\n",
      "       [    0.40625,     0.69583],\n",
      "       [    0.40469,     0.69375],\n",
      "       [    0.40469,     0.68958],\n",
      "       [    0.40312,      0.6875],\n",
      "       [    0.40312,     0.68125],\n",
      "       [    0.40156,     0.67917],\n",
      "       [    0.40156,       0.675],\n",
      "       [        0.4,     0.67292],\n",
      "       [        0.4,     0.66875],\n",
      "       [    0.39844,     0.66667],\n",
      "       [    0.39844,      0.6625],\n",
      "       [    0.39687,     0.66042],\n",
      "       [    0.39687,     0.65833],\n",
      "       [    0.39531,     0.65625],\n",
      "       [    0.39531,     0.65208],\n",
      "       [    0.39375,        0.65],\n",
      "       [    0.39375,     0.64375],\n",
      "       [    0.39219,     0.64167],\n",
      "       [    0.39219,      0.6375],\n",
      "       [    0.39062,     0.63542],\n",
      "       [    0.39062,     0.63125],\n",
      "       [    0.38906,     0.62917],\n",
      "       [    0.38906,       0.625],\n",
      "       [     0.3875,     0.62292],\n",
      "       [     0.3875,     0.61875],\n",
      "       [    0.38594,     0.61667],\n",
      "       [    0.38594,      0.6125],\n",
      "       [    0.38438,     0.61042],\n",
      "       [    0.38438,     0.60625],\n",
      "       [    0.38281,     0.60417],\n",
      "       [    0.38281,     0.60208],\n",
      "       [    0.38125,         0.6],\n",
      "       [    0.38125,     0.59792],\n",
      "       [    0.37969,     0.59583],\n",
      "       [    0.37969,     0.59167],\n",
      "       [    0.37813,     0.58958],\n",
      "       [    0.37813,     0.58333],\n",
      "       [    0.37656,     0.58125],\n",
      "       [    0.37656,     0.57708],\n",
      "       [      0.375,       0.575],\n",
      "       [      0.375,     0.56875],\n",
      "       [    0.37344,     0.56667],\n",
      "       [    0.37344,     0.56042],\n",
      "       [    0.37187,     0.55833],\n",
      "       [    0.37187,     0.54792],\n",
      "       [    0.37031,     0.54583],\n",
      "       [    0.37031,     0.52917],\n",
      "       [    0.36875,     0.52708],\n",
      "       [    0.36875,     0.49792],\n",
      "       [    0.37031,     0.49583],\n",
      "       [    0.37031,     0.47292],\n",
      "       [    0.36875,     0.47083],\n",
      "       [    0.36875,     0.44583],\n",
      "       [    0.36719,     0.44375],\n",
      "       [    0.36719,     0.41667],\n",
      "       [    0.36875,     0.41458],\n",
      "       [    0.36875,     0.40625],\n",
      "       [    0.36719,     0.40417],\n",
      "       [    0.36719,     0.40208],\n",
      "       [    0.36875,         0.4],\n",
      "       [    0.36875,     0.37083]], dtype=float32), array([[    0.65469,      0.3625],\n",
      "       [    0.65469,       0.375],\n",
      "       [    0.65625,     0.37708],\n",
      "       [    0.65625,     0.37917],\n",
      "       [    0.65469,     0.38125],\n",
      "       [    0.65469,      0.3875],\n",
      "       [    0.65312,     0.38958],\n",
      "       [    0.65312,     0.39583],\n",
      "       [    0.65156,     0.39792],\n",
      "       [    0.65156,       0.425],\n",
      "       [       0.65,     0.42708],\n",
      "       [       0.65,     0.45625],\n",
      "       [    0.65156,     0.45833],\n",
      "       [    0.65156,     0.47292],\n",
      "       [       0.65,       0.475],\n",
      "       [       0.65,     0.48125],\n",
      "       [    0.64844,     0.48333],\n",
      "       [    0.64844,     0.55208],\n",
      "       [    0.64688,     0.55417],\n",
      "       [    0.64688,      0.5625],\n",
      "       [    0.64531,     0.56458],\n",
      "       [    0.64531,     0.56875],\n",
      "       [    0.64375,     0.57083],\n",
      "       [    0.64375,     0.57708],\n",
      "       [    0.64219,     0.57917],\n",
      "       [    0.64219,     0.58125],\n",
      "       [    0.64062,     0.58333],\n",
      "       [    0.64062,     0.58958],\n",
      "       [    0.63906,     0.59167],\n",
      "       [    0.63906,     0.59583],\n",
      "       [     0.6375,     0.59792],\n",
      "       [     0.6375,     0.60208],\n",
      "       [    0.63594,     0.60417],\n",
      "       [    0.63594,     0.61667],\n",
      "       [    0.63437,     0.61875],\n",
      "       [    0.63437,     0.62708],\n",
      "       [    0.63281,     0.62917],\n",
      "       [    0.63281,     0.63125],\n",
      "       [    0.63125,     0.63333],\n",
      "       [    0.63125,     0.63542],\n",
      "       [    0.62969,      0.6375],\n",
      "       [    0.62969,     0.63958],\n",
      "       [    0.62813,     0.64167],\n",
      "       [    0.62813,     0.64583],\n",
      "       [    0.62656,     0.64792],\n",
      "       [    0.62656,     0.65208],\n",
      "       [      0.625,     0.65417],\n",
      "       [      0.625,     0.67917],\n",
      "       [    0.62344,     0.68125],\n",
      "       [    0.62344,     0.69583],\n",
      "       [    0.62187,     0.69792],\n",
      "       [    0.62187,     0.70208],\n",
      "       [    0.62031,     0.70417],\n",
      "       [    0.62031,     0.70833],\n",
      "       [    0.61875,     0.71042],\n",
      "       [    0.61875,      0.7125],\n",
      "       [    0.61719,     0.71458],\n",
      "       [    0.61719,     0.71667],\n",
      "       [    0.61094,       0.725],\n",
      "       [    0.60938,       0.725],\n",
      "       [    0.60938,     0.72708],\n",
      "       [    0.60781,     0.72917],\n",
      "       [    0.60781,     0.75208],\n",
      "       [    0.60625,     0.75417],\n",
      "       [    0.60625,     0.76667],\n",
      "       [    0.60469,     0.76875],\n",
      "       [    0.60469,     0.79375],\n",
      "       [    0.60312,     0.79583],\n",
      "       [    0.60312,     0.80417],\n",
      "       [    0.60156,     0.80625],\n",
      "       [    0.60156,     0.80833],\n",
      "       [        0.6,     0.81042],\n",
      "       [        0.6,     0.81458],\n",
      "       [    0.59844,     0.81667],\n",
      "       [    0.59844,     0.82708],\n",
      "       [    0.59688,     0.82917],\n",
      "       [    0.59688,     0.83958],\n",
      "       [    0.59531,     0.84167],\n",
      "       [    0.59531,     0.85208],\n",
      "       [    0.59375,     0.85417],\n",
      "       [    0.59375,     0.85625],\n",
      "       [    0.59219,     0.85833],\n",
      "       [    0.59219,      0.8625],\n",
      "       [    0.59062,     0.86458],\n",
      "       [    0.59062,     0.86875],\n",
      "       [    0.59219,     0.87083],\n",
      "       [    0.59219,     0.87292],\n",
      "       [    0.59531,     0.87708],\n",
      "       [    0.59531,     0.88958],\n",
      "       [    0.59375,     0.89167],\n",
      "       [    0.59375,     0.90208],\n",
      "       [    0.59219,     0.90417],\n",
      "       [    0.59219,     0.90625],\n",
      "       [    0.59062,     0.90833],\n",
      "       [    0.58438,     0.90833],\n",
      "       [    0.58438,     0.98958],\n",
      "       [    0.59062,     0.98958],\n",
      "       [    0.59531,     0.99583],\n",
      "       [    0.59531,     0.99792],\n",
      "       [    0.60312,     0.99792],\n",
      "       [    0.60312,     0.99583],\n",
      "       [    0.60469,     0.99375],\n",
      "       [     0.6125,     0.99375],\n",
      "       [    0.61406,     0.99583],\n",
      "       [    0.61406,     0.99792],\n",
      "       [     0.8125,     0.99792],\n",
      "       [     0.8125,      0.9875],\n",
      "       [    0.81406,     0.98542],\n",
      "       [     0.8125,     0.98333],\n",
      "       [     0.8125,        0.95],\n",
      "       [    0.81094,     0.94792],\n",
      "       [    0.81094,     0.93333],\n",
      "       [     0.8125,     0.93125],\n",
      "       [     0.8125,     0.92708],\n",
      "       [    0.81094,       0.925],\n",
      "       [    0.81094,     0.87708],\n",
      "       [    0.80937,       0.875],\n",
      "       [    0.80937,     0.86667],\n",
      "       [    0.80781,     0.86458],\n",
      "       [    0.80781,     0.86042],\n",
      "       [    0.80937,     0.85833],\n",
      "       [    0.80937,     0.85417],\n",
      "       [    0.81094,     0.85208],\n",
      "       [    0.81094,     0.84375],\n",
      "       [    0.80937,     0.84167],\n",
      "       [    0.80937,       0.825],\n",
      "       [    0.81094,     0.82292],\n",
      "       [    0.81094,     0.81458],\n",
      "       [    0.80937,      0.8125],\n",
      "       [    0.80937,     0.80625],\n",
      "       [    0.80781,     0.80417],\n",
      "       [    0.80781,     0.79583],\n",
      "       [    0.80625,     0.79375],\n",
      "       [    0.80625,     0.79167],\n",
      "       [    0.80469,     0.78958],\n",
      "       [    0.80469,     0.77292],\n",
      "       [    0.80625,     0.77083],\n",
      "       [    0.80625,     0.73958],\n",
      "       [    0.80781,      0.7375],\n",
      "       [    0.80781,     0.73542],\n",
      "       [    0.80625,     0.73333],\n",
      "       [    0.80625,     0.71458],\n",
      "       [    0.80469,      0.7125],\n",
      "       [    0.80469,     0.69375],\n",
      "       [    0.80313,     0.69167],\n",
      "       [    0.80313,     0.68542],\n",
      "       [    0.80156,     0.68333],\n",
      "       [    0.80156,     0.67917],\n",
      "       [        0.8,     0.67708],\n",
      "       [        0.8,       0.675],\n",
      "       [    0.79688,     0.67083],\n",
      "       [    0.79688,     0.66042],\n",
      "       [    0.79531,     0.65833],\n",
      "       [    0.79531,     0.64375],\n",
      "       [    0.79375,     0.64167],\n",
      "       [    0.79375,     0.62917],\n",
      "       [    0.79219,     0.62708],\n",
      "       [    0.79219,     0.56667],\n",
      "       [    0.79375,     0.56458],\n",
      "       [    0.79375,     0.55833],\n",
      "       [    0.79531,     0.55625],\n",
      "       [    0.79531,     0.53958],\n",
      "       [    0.79688,      0.5375],\n",
      "       [    0.79688,     0.51875],\n",
      "       [    0.79844,     0.51667],\n",
      "       [    0.79844,     0.50625],\n",
      "       [        0.8,     0.50417],\n",
      "       [        0.8,     0.49792],\n",
      "       [    0.80156,     0.49583],\n",
      "       [    0.80156,     0.49167],\n",
      "       [    0.80313,     0.48958],\n",
      "       [    0.80313,       0.475],\n",
      "       [    0.80469,     0.47292],\n",
      "       [    0.80469,     0.46458],\n",
      "       [    0.80625,      0.4625],\n",
      "       [    0.80625,     0.45833],\n",
      "       [    0.80781,     0.45625],\n",
      "       [    0.80781,     0.45208],\n",
      "       [    0.80937,        0.45],\n",
      "       [    0.80937,     0.44792],\n",
      "       [    0.81094,     0.44583],\n",
      "       [    0.81094,     0.44375],\n",
      "       [     0.8125,     0.44167],\n",
      "       [     0.8125,      0.4375],\n",
      "       [    0.81406,     0.43542],\n",
      "       [    0.81406,     0.43125],\n",
      "       [    0.81563,     0.42917],\n",
      "       [    0.81563,       0.425],\n",
      "       [    0.81719,     0.42292],\n",
      "       [    0.81719,     0.42083],\n",
      "       [    0.81875,     0.41875],\n",
      "       [    0.81875,     0.41458],\n",
      "       [    0.82031,      0.4125],\n",
      "       [    0.82031,     0.41042],\n",
      "       [      0.825,     0.40417],\n",
      "       [    0.82344,     0.40208],\n",
      "       [    0.82344,         0.4],\n",
      "       [    0.82031,     0.39583],\n",
      "       [    0.81875,     0.39583],\n",
      "       [    0.81719,     0.39375],\n",
      "       [    0.81563,     0.39375],\n",
      "       [     0.8125,     0.38958],\n",
      "       [    0.81094,     0.38958],\n",
      "       [    0.80937,      0.3875],\n",
      "       [    0.80781,      0.3875],\n",
      "       [    0.80625,     0.38542],\n",
      "       [    0.80313,     0.38542],\n",
      "       [    0.80156,     0.38333],\n",
      "       [        0.8,     0.38333],\n",
      "       [    0.79844,     0.38125],\n",
      "       [    0.79531,     0.38125],\n",
      "       [    0.79375,     0.37917],\n",
      "       [    0.79219,     0.37917],\n",
      "       [    0.79062,     0.37708],\n",
      "       [    0.77344,     0.37708],\n",
      "       [    0.75156,     0.40625],\n",
      "       [       0.75,     0.40625],\n",
      "       [    0.74687,     0.41042],\n",
      "       [    0.74531,     0.41042],\n",
      "       [    0.74219,     0.41458],\n",
      "       [    0.74063,     0.41458],\n",
      "       [    0.72188,     0.43958],\n",
      "       [    0.71094,     0.43958],\n",
      "       [    0.70625,     0.43333],\n",
      "       [    0.70625,     0.43125],\n",
      "       [    0.70469,     0.42917],\n",
      "       [    0.70469,     0.42708],\n",
      "       [    0.70312,       0.425],\n",
      "       [    0.70312,     0.42292],\n",
      "       [    0.70156,     0.42083],\n",
      "       [    0.70156,     0.41667],\n",
      "       [        0.7,     0.41458],\n",
      "       [        0.7,      0.4125],\n",
      "       [    0.69844,     0.41042],\n",
      "       [    0.69844,     0.40833],\n",
      "       [    0.69531,     0.40417],\n",
      "       [    0.69531,     0.40208],\n",
      "       [    0.69375,         0.4],\n",
      "       [    0.69375,     0.39792],\n",
      "       [    0.69219,     0.39583],\n",
      "       [    0.69219,     0.39375],\n",
      "       [    0.69063,     0.39167],\n",
      "       [    0.69063,      0.3875],\n",
      "       [    0.68906,     0.38542],\n",
      "       [    0.68906,     0.38333],\n",
      "       [     0.6875,     0.38125],\n",
      "       [     0.6875,     0.37917],\n",
      "       [    0.68594,     0.37708],\n",
      "       [    0.68594,     0.37292],\n",
      "       [    0.68437,     0.37083],\n",
      "       [    0.68437,      0.3625]], dtype=float32)]\n",
      "Speed: 2.2ms preprocess, 45.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "# Inference \n",
    "\n",
    "# Load your trained model\n",
    "model = YOLO(r\"runs/Run_full_pt_pretrainTrue_continue7/weights/best.pt\")\n",
    "\n",
    "# List of test images\n",
    "test_images = [\n",
    "    #r\"E:/Techlabs_AI/digital_wardrobe/eWardrobe/datasets/YOLOfull/test/images/000011.jpg\",\n",
    "    r\"E:/Techlabs_AI/digital_wardrobe/test/5.jpeg\"\n",
    "]\n",
    "\n",
    "# Run inference\n",
    "results = model(test_images, stream=True)\n",
    "\n",
    "# Process results\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"\\n🔹 Results for image {i+1}:\")\n",
    "    print(\"Boxes:\", result.boxes)   # bounding box info\n",
    "    print(\"Masks:\", result.masks)   # segmentation masks\n",
    "    result.show()                   # show image with predictions\n",
    "    result.save(filename=f\"prediction_{i+1}.jpg\")  # save annotated image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4657e4",
   "metadata": {},
   "source": [
    "Estimation of training time for improved results:\n",
    "\n",
    "| Model          | Img size | Time / epoch | Time for 100 epochs   |\n",
    "| -------------- | -------- | ------------ | --------------------- |\n",
    "| **n (nano)**   | 640      | \\~22 min     | \\~37 h                |\n",
    "| **n (nano)**   | 896      | \\~44 min     | \\~73 h (\\~3 days)     |\n",
    "| **n (nano)**   | 1024     | \\~55 min     | \\~91 h (\\~3.8 days)   |\n",
    "| **s (small)**  | 640      | \\~44 min     | \\~73 h (\\~3 days)     |\n",
    "| **s (small)**  | 896      | \\~88 min     | \\~146 h (\\~6 days)    |\n",
    "| **s (small)**  | 1024     | \\~110 min    | \\~183 h (\\~7.5 days)  |\n",
    "| **m (medium)** | 640      | \\~77 min     | \\~128 h (\\~5.3 days)  |\n",
    "| **m (medium)** | 896      | \\~154 min    | \\~256 h (\\~10.5 days) |\n",
    "| **m (medium)** | 1024     | \\~192 min    | \\~320 h (\\~13 days)   |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv312 (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
